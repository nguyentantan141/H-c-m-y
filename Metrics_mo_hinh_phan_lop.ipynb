{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UlZYJCozH2BS"
      ],
      "authorship_tag": "ABX9TyO7B4KJXeX16VkWeZdeml/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyentantan141/MACHINE-LEARNING/blob/Machine-learning/Metrics_mo_hinh_phan_lop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "wpqtCynTZLNr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from scipy import optimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpj31mSsLs8N",
        "outputId": "acd30a74-9a80-4447-8079-17c7732169d7"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đọc dữ liệu"
      ],
      "metadata": {
        "id": "zu5LTA-OYoqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readData(pathfolder: str, filename: str):\n",
        "  data=np.loadtxt(os.path.join(pathfolder, filename),delimiter=',')\n",
        "  X, y = data[:,:-1], data[:, -1]\n",
        "  m = X.shape[0]\n",
        "  n = X.shape[1]\n",
        "  X = np.reshape(X, (m,n))\n",
        "  y = np.reshape(y, (m,1))\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "cngSjt3-L8n5"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chuẩn hóa dữ liệu"
      ],
      "metadata": {
        "id": "fDS5EZ1GYriE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling_minmax_norm(data):\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  #Phải thực hiện thao tác fit(data) trước khi điều chỉnh dữ liệu\n",
        "  scaler.fit(data)\n",
        "  #Thực hiện điều chỉnh dữ liệu\n",
        "  data = scaler.transform(data)\n",
        "  return data"
      ],
      "metadata": {
        "id": "8jaFYAEHL-lR"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling_X(X):\n",
        "    X_scl=scaling_minmax_norm(X)\n",
        "    m=X.shape[0]\n",
        "    X_scl=np.hstack((np.ones((m,1)),X_scl))\n",
        "    return X_scl"
      ],
      "metadata": {
        "id": "234lWeh-hWgD"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X,y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=15)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "mVciKCzJMAe9"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "PA2q9cGfYwik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(X, w):\n",
        "  result = 1/(1 + np.exp(-np.dot(X, w)))\n",
        "  return result\n",
        "\n",
        "def predict(y_hat):\n",
        "    return np.rint(y_hat)\n",
        "\n",
        "def loss(X, y,w):\n",
        "  m=y.shape[0]\n",
        "  h=sigmoid(X,w)\n",
        "  result = (-1 / m) * np.sum(np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))\n",
        "  return result\n",
        "\n",
        "def gradient(X, y, w):\n",
        "    m = X.shape[0]\n",
        "    result = (1/m)*np.dot(X.T, sigmoid(X, w) - y)\n",
        "    return result\n",
        "\n",
        "def gradientDescent(X, y, w, alpha, n_iters):\n",
        "    w_optimal = w.copy()\n",
        "    J_history = []\n",
        "    for i in range(n_iters):\n",
        "        w_optimal = w_optimal - alpha*gradient(X, y, w_optimal)\n",
        "        J_history.append(loss(X, y, w_optimal))\n",
        "    return w_optimal, J_history\n"
      ],
      "metadata": {
        "id": "wsuiBZMBYd_d"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Độ đo"
      ],
      "metadata": {
        "id": "UlZYJCozH2BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy "
      ],
      "metadata": {
        "id": "ewOaFvYDPGKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_score(y, y_hat): \n",
        " m = y.shape[0] \n",
        " result = (1/m)*np.sum(y == y_hat)  \n",
        " return result\n"
      ],
      "metadata": {
        "id": "PKSszM1qPJJg"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top-k accuracy"
      ],
      "metadata": {
        "id": "VuxCuWSAGPHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_acc(y,f_hat):\n",
        "  m=f_hat.shape[0]\n",
        "  n=f_hat.shape[1]\n",
        "  a=0\n",
        "  for i in range(m):\n",
        "    if y[i]in f_hat[i]:\n",
        "      a+=1\n",
        "  result=a/m\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "PUcKXGsbwW9g"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanced accuracy"
      ],
      "metadata": {
        "id": "0kDYBNn5GUFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def balanced_accuracy(y,y_hat):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
        "  result=0.5*(tp/(tp+fn)+tn/(tn+fp))\n",
        "  return result "
      ],
      "metadata": {
        "id": "cj3QzbKGEyqZ"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision"
      ],
      "metadata": {
        "id": "FgCcaVpaGXft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(y,y_hat):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
        "  result=tp/(tp+fp)\n",
        "  return result"
      ],
      "metadata": {
        "id": "eIEsqC9xGjDV"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall"
      ],
      "metadata": {
        "id": "PGj4R6_pGcpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y,y_hat):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
        "  result=tp/(tp+fn)\n",
        "  return result"
      ],
      "metadata": {
        "id": "viGVhLK_G8ay"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1 (F-measure)"
      ],
      "metadata": {
        "id": "ahTspVk5GeQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(y,y_hat):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
        "  precision=tp/(tp+fp)\n",
        "  recall=tp/(tp+fn)\n",
        "  result=2*((precision*recall)/(precision+recall))\n",
        "  return result"
      ],
      "metadata": {
        "id": "ialAi4cTHIK9"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(y_pred):\n",
        "    return np.rint(y_pred)"
      ],
      "metadata": {
        "id": "rxXWi_W8RGwR"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đánh giá mô hình\n"
      ],
      "metadata": {
        "id": "2iWTdlcHLMKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    X,y=readData('/content/drive/MyDrive/Data/data/','ex2data1.txt')\n",
        "    X_scl=scaling_X(X)\n",
        "    X_train, X_test, y_train, y_test = split_data(X_scl,y)\n",
        "    print('Huấn luyện mô hình trên tập dữ liệu train')\n",
        "    n = X_scl.shape[1]\n",
        "    w = np.zeros((n, 1)).reshape([n,1])\n",
        "    alpha = 0.01\n",
        "    n_iters = 2000\n",
        "    w_opt, J_hist = gradientDescent(X_train, y_train, w, alpha, n_iters)\n",
        "    print(\"Ket qua huan luyen mo hinh la: \")\n",
        "    print('\\t\\tTrong so w toi uu la:\\n ', w_opt)\n",
        "    print('Ket qua du doan cua mo hinh')\n",
        "    y_hat = predict(sigmoid(X_test, w_opt))\n",
        "    print('\\t\\tChỉ số Accuracy: ', acc_score(y_test, y_hat))\n",
        "    print('\\t\\tSử dụng sklearn, Acc: ', accuracy_score(y_test, y_hat))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjCKL5J4LsCR",
        "outputId": "e8106ef5-f5c7-4ad3-db5f-9420bb4532eb"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Huấn luyện mô hình trên tập dữ liệu train\n",
            "Ket qua huan luyen mo hinh la: \n",
            "\t\tTrong so w toi uu la:\n",
            "  [[-0.54745078]\n",
            " [ 0.99213425]\n",
            " [ 1.01929404]]\n",
            "Ket qua du doan cua mo hinh\n",
            "\t\tChỉ số Accuracy:  0.7333333333333333\n",
            "\t\tSử dụng sklearn, Acc:  0.7333333333333333\n"
          ]
        }
      ]
    }
  ]
}